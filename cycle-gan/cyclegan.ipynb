{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, metadata = tfds.load('cycle_gan/apple2orange',\n",
    "                              with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_monet, train_photo = dataset['trainA'], dataset['trainB']\n",
    "test_monet, test_photo = dataset['testA'], dataset['testB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "def format_image(image,label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/127.5) - 1\n",
    "    image = tf.image.resize(image,(IMG_SIZE,IMG_SIZE))\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "train_monet = train_monet.map(format_image).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "train_photo = train_photo.map(format_image).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_monet = test_monet.map(format_image).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_photo = test_photo.map(format_image).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset = tf.data.Dataset.zip((train_monet, train_photo)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_apple = next(iter(train_monet))\n",
    "sample_orange = next(iter(train_photo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectionPad2d(tf.keras.layers.Layer):\n",
    "    def __init__(self, padding, **kwargs):\n",
    "        super(ReflectionPad2d, self).__init__(**kwargs)\n",
    "        self.padding = [[0, 0], [padding, padding], [padding, padding], [0, 0]]\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return tf.pad(inputs, self.padding, 'REFLECT')\n",
    "\n",
    "\n",
    "class ResNetBlock(tf.keras.Model):\n",
    "    def __init__(self, dim):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.padding1 = ReflectionPad2d(1)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(dim, (3, 3), padding='valid', use_bias=False)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu1 = tf.keras.layers.ReLU()\n",
    "\n",
    "        self.padding2 = ReflectionPad2d(1)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(dim, (3, 3), padding='valid', use_bias=False)\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = self.padding1(inputs)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.padding2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        outputs = inputs + x\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model(n_blocks):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Encoding\n",
    "    model.add(ReflectionPad2d(3, input_shape=(256, 256, 3)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (7, 7), strides=(1, 1), padding='valid', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    # Transformation\n",
    "    for i in range(n_blocks):\n",
    "        model.add(ResNetBlock(256))\n",
    "\n",
    "    # Decoding\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(ReflectionPad2d(3))\n",
    "    model.add(tf.keras.layers.Conv2D(3, (7, 7), strides=(1, 1), padding='valid', activation='tanh'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(3, (4, 4), strides=(2, 2), padding='same', input_shape=(256, 256, 3)))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Conv2D(512, (4, 4), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Conv2D(1, (4, 4), strides=(1, 1), padding='same'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_a2b = make_generator_model(9)\n",
    "generator_b2a = make_generator_model(9)\n",
    "discriminator_b = make_discriminator_model()\n",
    "discriminator_a = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gan_loss(prediction, is_real):\n",
    "    if is_real:\n",
    "        return losses(prediction, tf.ones_like(prediction))\n",
    "    else:\n",
    "        return losses(prediction, tf.zeros_like(prediction))\n",
    "\n",
    "def calc_cycle_loss(reconstructed_images, real_images):\n",
    "    return losses(reconstructed_images, real_images)\n",
    "\n",
    "def calc_identity_loss(identity_images, real_images):\n",
    "    return losses(identity_images, real_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_generator(images_a, images_b):\n",
    "    real_a = images_a\n",
    "    real_b = images_b\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Use real B to generate B should be identical\n",
    "        identity_a2b = generator_a2b(real_b, training=True)\n",
    "        identity_b2a = generator_b2a(real_a, training=True)\n",
    "        loss_identity_a2b = calc_identity_loss(identity_a2b, real_b)\n",
    "        loss_identity_b2a = calc_identity_loss(identity_b2a, real_a)\n",
    "\n",
    "        # Generator A2B tries to trick Discriminator B that the generated image is B\n",
    "        loss_gan_gen_a2b = calc_gan_loss(discriminator_b(fake_a2b, training=True), True)\n",
    "        # Generator B2A tries to trick Discriminator A that the generated image is A\n",
    "        loss_gan_gen_b2a = calc_gan_loss(discriminator_a(fake_b2a, training=True), True)\n",
    "        loss_cycle_a2b2a = calc_cycle_loss(recon_b2a, real_a)\n",
    "        loss_cycle_b2a2b = calc_cycle_loss(recon_a2b, real_b)\n",
    "\n",
    "        # Total generator loss\n",
    "        loss_gen_total = loss_gan_gen_a2b + loss_gan_gen_b2a \\\n",
    "            + (loss_cycle_a2b2a + loss_cycle_b2a2b) * 10 \\\n",
    "            + (loss_identity_a2b + loss_identity_b2a) * 5\n",
    "\n",
    "    trainable_variables = generator_a2b.trainable_variables + generator_b2a.trainable_variables\n",
    "    gradient_gen = tape.gradient(loss_gen_total, trainable_variables)\n",
    "    optimizer_gen.apply_gradients(zip(gradient_gen, trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_discriminator(images_a, images_b, fake_a2b, fake_b2a):\n",
    "    real_a = images_a\n",
    "    real_b = images_b\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # Discriminator A should classify real_a as A\n",
    "        loss_gan_dis_a_real = calc_gan_loss(discriminator_a(real_a, training=True), True)\n",
    "        # Discriminator A should classify generated fake_b2a as not A\n",
    "        loss_gan_dis_a_fake = calc_gan_loss(discriminator_a(fake_b2a, training=True), False)\n",
    "\n",
    "        # Discriminator B should classify real_b as B\n",
    "        loss_gan_dis_b_real = calc_gan_loss(discriminator_b(real_b, training=True), True)\n",
    "        # Discriminator B should classify generated fake_a2b as not B\n",
    "        loss_gan_dis_b_fake = calc_gan_loss(discriminator_b(fake_a2b, training=True), False)\n",
    "\n",
    "        # Total discriminator loss\n",
    "        loss_dis_a = (loss_gan_dis_a_real + loss_gan_dis_a_fake) * 0.5\n",
    "        loss_dis_b = (loss_gan_dis_b_real + loss_gan_dis_b_fake) * 0.5\n",
    "        loss_dis_total = loss_dis_a + loss_dis_b\n",
    "\n",
    "    trainable_variables = discriminator_a.trainable_variables + discriminator_b.trainable_variables\n",
    "    gradient_dis = tape.gradient(loss_dis_total, trainable_variables)\n",
    "    optimizer_dis.apply_gradients(zip(gradient_dis, trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images_a, images_b, epoch, step):\n",
    "    fake_a2b, fake_b2a, gen_loss_dict = train_generator(images_a, images_b)\n",
    "\n",
    "    fake_b2a_from_pool = fake_pool_b2a.query(fake_b2a)\n",
    "    fake_a2b_from_pool = fake_pool_a2b.query(fake_a2b)\n",
    "\n",
    "    dis_loss_dict = train_discriminator(images_a, images_b, fake_a2b_from_pool, fake_b2a_from_pool)\n",
    "\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for (step, batch) in enumerate(dataset):\n",
    "            train_step(batch[0], batch[1], epoch, step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
