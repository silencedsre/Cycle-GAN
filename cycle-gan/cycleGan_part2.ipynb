{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCvkDK8M45fo"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.layers import InstanceNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YOLygRYn45fs"
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QRE6WAY_45fu"
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQJMNNZb45fw"
   },
   "outputs": [],
   "source": [
    "dataset, metadata = tfds.load('cycle_gan/apple2orange',\n",
    "                              with_info=True, as_supervised=True, data_dir='../../deep learning/cyclegan/dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yE78cmZp45fy"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nPwFifa945f1"
   },
   "outputs": [],
   "source": [
    "train_monet, train_photo = dataset['trainA'], dataset['trainB']\n",
    "test_monet, test_photo = dataset['testA'], dataset['testB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dz6ERtq45f3"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "def format_image(image,_):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/127.5) - 1\n",
    "    image = tf.image.resize(image,(IMG_SIZE,IMG_SIZE))\n",
    "    return tf.reshape(image,(1, IMG_SIZE, IMG_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EAO540Ai45f5"
   },
   "outputs": [],
   "source": [
    "train_monet = train_monet.map(format_image)\n",
    "train_photo = train_photo.map(format_image)\n",
    "test_monet = test_monet.map(format_image)\n",
    "test_photo = test_photo.map(format_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVNJjy0O45f8"
   },
   "outputs": [],
   "source": [
    "# train_monet = tf.data.Dataset.from_tensors(train_monet)\n",
    "# train_photo = tf.data.Dataset.from_tensors(train_photo)\n",
    "# test_monet = tf.data.Dataset.from_tensors(test_monet)\n",
    "# test_photo = tf.data.Dataset.from_tensors(test_photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6GFFfaW45f9"
   },
   "outputs": [],
   "source": [
    "train_monet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_nlq0BfK45gC"
   },
   "outputs": [],
   "source": [
    "combined_dataset = tf.data.Dataset.zip((train_monet, train_photo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oEN63Iys45gF"
   },
   "outputs": [],
   "source": [
    "sample_apple = next(iter(train_monet))\n",
    "sample_orange = next(iter(train_photo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wMGWKXxf45gH"
   },
   "outputs": [],
   "source": [
    "class ReflectionPad2d(tf.keras.layers.Layer):\n",
    "    def __init__(self, padding, **kwargs):\n",
    "        super(ReflectionPad2d, self).__init__(**kwargs)\n",
    "        self.padding = [[0, 0], [padding, padding], [padding, padding], [0, 0]]\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return tf.pad(inputs, self.padding, 'REFLECT')\n",
    "\n",
    "\n",
    "class ResNetBlock(tf.keras.Model):\n",
    "    def __init__(self, dim):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.padding1 = ReflectionPad2d(1)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(dim, (3, 3), padding='valid', use_bias=False)\n",
    "        self.bn1 = tf.keras.layers.InstanceNormalization()\n",
    "        self.relu1 = tf.keras.layers.ReLU()\n",
    "\n",
    "        self.padding2 = ReflectionPad2d(1)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(dim, (3, 3), padding='valid', use_bias=False)\n",
    "        self.bn2 = tf.keras.layers.InstanceNormalization()\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = self.padding1(inputs)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.padding2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        outputs = inputs + x\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AXHyZSv345gI"
   },
   "outputs": [],
   "source": [
    "def make_generator_model(n_blocks):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Encoding\n",
    "    model.add(ReflectionPad2d(3, input_shape=(256, 256, 3)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (7, 7), strides=(1, 1), padding='valid', use_bias=False))\n",
    "    model.add(tf.keras.layers.InstanceNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.InstanceNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.InstanceNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    # Transformation\n",
    "    for i in range(n_blocks):\n",
    "        model.add(ResNetBlock(256))\n",
    "\n",
    "    # Decoding\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.InstanceNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.InstanceNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(ReflectionPad2d(3))\n",
    "    model.add(tf.keras.layers.Conv2D(3, (7, 7), strides=(1, 1), padding='valid', activation='tanh'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8EhWGo1U45gK"
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(3, (4, 4), strides=(2, 2), padding='same', input_shape=(256, 256, 3)))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.InstanceNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.InstanceNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Conv2D(512, (4, 4), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.InstanceNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Conv2D(1, (4, 4), strides=(1, 1), padding='same'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3OdvSlXZ45gM"
   },
   "outputs": [],
   "source": [
    "generator_g = make_generator_model(9)\n",
    "generator_f = make_generator_model(9)\n",
    "discriminator_x = make_discriminator_model()\n",
    "discriminator_y = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xw6AjiYM45gO"
   },
   "outputs": [],
   "source": [
    "discriminator_x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GMOGIot66b_w"
   },
   "outputs": [],
   "source": [
    "LAMBDA = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GF4SOtp5-GV"
   },
   "outputs": [],
   "source": [
    "gen_g_optimizer = gen_f_optimizer = tf.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "dis_x_optimizer = dis_y_optimizer = tf.optimizers.Adam(lr=0.0002, beta_1=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VBsH9kex45gQ"
   },
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Measures how close to one real images are rated, and how close to zero fake images are rated\n",
    "def discriminator_loss(real, generated):\n",
    "    # Multiplied by 0.5 so that it will train at half-speed\n",
    "    return (loss(tf.ones_like(real), real) + loss(tf.zeros_like(generated), generated)) * 0.5\n",
    "\n",
    "# Measures how real the discriminator believes the fake image is\n",
    "def gen_loss(validity):\n",
    "    return loss(tf.ones_like(validity), validity)\n",
    "\n",
    "# Measures similarity of two images.  Used for cycle and identity loss\n",
    "def image_similarity(image1, image2):\n",
    "    return tf.reduce_mean(tf.abs(image1 - image2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0G7HF_uI45gS"
   },
   "outputs": [],
   "source": [
    "def step(real_x, real_y):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Setup Dy loss\n",
    "        fake_y = generator_g(real_x, training=True)\n",
    "        gen_g_validity = discriminator_y(fake_y, training=True)\n",
    "        dis_y_loss = discriminator_loss(discriminator_y(real_y, training=True), gen_g_validity)\n",
    "\n",
    "        with tape.stop_recording():\n",
    "            discriminator_y_gradients = tape.gradient(dis_y_loss, discriminator_y.trainable_variables)\n",
    "            dis_y_optimizer.apply_gradients(zip(discriminator_y_gradients, discriminator_y.trainable_variables))\n",
    "\n",
    "        # Setup Dx loss\n",
    "        fake_x = generator_f(real_y, training=True)\n",
    "        gen_f_validity = discriminator_x(fake_x, training=True)\n",
    "        dis_x_loss = discriminator_loss(discriminator_x(real_x, training=True), gen_f_validity)\n",
    "\n",
    "        with tape.stop_recording():\n",
    "            discriminator_x_gradients = tape.gradient(dis_x_loss, discriminator_x.trainable_variables)\n",
    "            dis_x_optimizer.apply_gradients(zip(discriminator_x_gradients, discriminator_x.trainable_variables))\n",
    "\n",
    "        # Setup adversarial losses\n",
    "        gen_g_adv_loss = gen_loss(gen_g_validity)\n",
    "        gen_f_adv_loss = gen_loss(gen_f_validity)\n",
    "\n",
    "        # Setup cycle losses\n",
    "        cyc_x = generator_f(fake_y, training=True)\n",
    "        cyc_x_loss = image_similarity(real_x, cyc_x)\n",
    "\n",
    "        cyc_y = generator_g(fake_x, training=True)\n",
    "        cyc_y_loss =  image_similarity(real_y, cyc_y)\n",
    "\n",
    "        # Setup identity losses\n",
    "        id_x = generator_f(real_x, training=True)\n",
    "        id_x_loss = image_similarity(real_x, id_x)\n",
    "\n",
    "        id_y = generator_g(real_y, training=True)\n",
    "        id_y_loss = image_similarity(real_y, id_y)\n",
    "\n",
    "        # Finalize generator losses and calc gradients\n",
    "        gen_g_loss = gen_g_adv_loss + (cyc_x_loss + cyc_y_loss) * LAMBDA + id_y_loss * 0.5*LAMBDA\n",
    "        gen_f_loss = gen_f_adv_loss + (cyc_x_loss + cyc_y_loss) * LAMBDA + id_x_loss * 0.5*LAMBDA\n",
    "\n",
    "        with tape.stop_recording():\n",
    "            generator_g_gradients = tape.gradient(gen_g_loss, generator_g.trainable_variables)\n",
    "            gen_g_optimizer.apply_gradients(zip(generator_g_gradients, generator_g.trainable_variables))\n",
    "\n",
    "            generator_f_gradients = tape.gradient(gen_f_loss, generator_f.trainable_variables)\n",
    "            gen_f_optimizer.apply_gradients(zip(generator_f_gradients, generator_f.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YH6jUyDn45gU"
   },
   "outputs": [],
   "source": [
    "    # Sample images\n",
    "    x = next(iter(test_monet.shuffle(1000))).numpy()\n",
    "    y = next(iter(test_photo.shuffle(1000))).numpy()\n",
    "    \n",
    "    # Get predictions for those images\n",
    "    y_hat = generator_g.predict(x.reshape((1, IMG_SIZE, IMG_SIZE, 3)))\n",
    "    x_hat = generator_f.predict(y.reshape((1, IMG_SIZE, IMG_SIZE, 3)))\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    images = [x[0], y_hat[0], y[0], x_hat[0]]\n",
    "\n",
    "    for i in range(4):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.imshow(images[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yDHHaXW1CkPf"
   },
   "outputs": [],
   "source": [
    "def generate_images():\n",
    "    # Sample images\n",
    "    x = next(iter(test_monet.shuffle(1000))).numpy()\n",
    "    y = next(iter(test_photo.shuffle(1000))).numpy()\n",
    "    \n",
    "    # Get predictions for those images\n",
    "    y_hat = generator_g.predict(x.reshape((1, IMG_SIZE, IMG_SIZE, 3)))\n",
    "    x_hat = generator_f.predict(y.reshape((1, IMG_SIZE, IMG_SIZE, 3)))\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    images = [x[0], y_hat[0], y[0], x_hat[0]]\n",
    "\n",
    "    for i in range(4):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.imshow(images[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"c:/users/khushee/Downloads/deeplearning\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           gen_g_optimizer=gen_g_optimizer,\n",
    "                           gen_f_optimizer=gen_f_optimizer,\n",
    "                           dis_x_optimizer=dis_x_optimizer,\n",
    "                           dis_y_optimizer=dis_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LZCMK-ZV45gW"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "epochs=50\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    start = time.time()\n",
    "\n",
    "    # Each batch\n",
    "    for k, (real_x, real_y) in enumerate(tf.data.Dataset.zip((train_monet, test_photo))):\n",
    "        if k % 100 == 0: print(k)\n",
    "        # Train step\n",
    "        step(tf.reshape(real_x, (1, IMG_SIZE, IMG_SIZE, 3)), tf.reshape(real_y, (1, IMG_SIZE, IMG_SIZE, 3)))\n",
    "    \n",
    "    # View progress\n",
    "    generate_images()\n",
    "    print('Time taken: {}'.format(time.time() - start))\n",
    "    if epoch<=50:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                          ckpt_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3tS2IWx45QF4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_hbBEQwNMIwl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cycleGan-part2.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
