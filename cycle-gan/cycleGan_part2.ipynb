{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "cycleGan-part2.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCvkDK8M45fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOLygRYn45fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRE6WAY_45fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQJMNNZb45fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset, metadata = tfds.load('cycle_gan/monet2photo',\n",
        "                              with_info=True, as_supervised=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE78cmZp45fy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPwFifa945f1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_monet, train_photo = dataset['trainA'], dataset['trainB']\n",
        "test_monet, test_photo = dataset['testA'], dataset['testB']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dz6ERtq45f3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 256\n",
        "def format_image(image,_):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = (image/127.5) - 1\n",
        "    image = tf.image.resize(image,(IMG_SIZE,IMG_SIZE))\n",
        "    return tf.reshape(image,(1, IMG_SIZE, IMG_SIZE, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAO540Ai45f5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_monet = train_monet.map(format_image)\n",
        "train_photo = train_photo.map(format_image)\n",
        "test_monet = test_monet.map(format_image)\n",
        "test_photo = test_photo.map(format_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVNJjy0O45f8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_monet = tf.data.Dataset.from_tensors(train_monet)\n",
        "# train_photo = tf.data.Dataset.from_tensors(train_photo)\n",
        "# test_monet = tf.data.Dataset.from_tensors(test_monet)\n",
        "# test_photo = tf.data.Dataset.from_tensors(test_photo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6GFFfaW45f9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_monet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhWYaT7p45f_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nlq0BfK45gC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_dataset = tf.data.Dataset.zip((train_monet, train_photo))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEN63Iys45gF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_apple = next(iter(train_monet))\n",
        "sample_orange = next(iter(train_photo))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMGWKXxf45gH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReflectionPad2d(tf.keras.layers.Layer):\n",
        "    def __init__(self, padding, **kwargs):\n",
        "        super(ReflectionPad2d, self).__init__(**kwargs)\n",
        "        self.padding = [[0, 0], [padding, padding], [padding, padding], [0, 0]]\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return tf.pad(inputs, self.padding, 'REFLECT')\n",
        "\n",
        "\n",
        "class ResNetBlock(tf.keras.Model):\n",
        "    def __init__(self, dim):\n",
        "        super(ResNetBlock, self).__init__()\n",
        "        self.padding1 = ReflectionPad2d(1)\n",
        "        self.conv1 = tf.keras.layers.Conv2D(dim, (3, 3), padding='valid', use_bias=False)\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu1 = tf.keras.layers.ReLU()\n",
        "\n",
        "        self.padding2 = ReflectionPad2d(1)\n",
        "        self.conv2 = tf.keras.layers.Conv2D(dim, (3, 3), padding='valid', use_bias=False)\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        x = self.padding1(inputs)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.padding2(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        outputs = inputs + x\n",
        "        return outputs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXHyZSv345gI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generator_model(n_blocks):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Encoding\n",
        "    model.add(ReflectionPad2d(3, input_shape=(256, 256, 3)))\n",
        "    model.add(tf.keras.layers.Conv2D(64, (7, 7), strides=(1, 1), padding='valid', use_bias=False))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    # Transformation\n",
        "    for i in range(n_blocks):\n",
        "        model.add(ResNetBlock(256))\n",
        "\n",
        "    # Decoding\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    model.add(ReflectionPad2d(3))\n",
        "    model.add(tf.keras.layers.Conv2D(3, (7, 7), strides=(1, 1), padding='valid', activation='tanh'))\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EhWGo1U45gK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(3, (4, 4), strides=(2, 2), padding='same', input_shape=(256, 256, 3)))\n",
        "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(tf.keras.layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(tf.keras.layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(tf.keras.layers.Conv2D(512, (4, 4), strides=(1, 1), padding='same', use_bias=False))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(tf.keras.layers.Conv2D(1, (4, 4), strides=(1, 1), padding='same'))\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OdvSlXZ45gM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_g = make_generator_model(9)\n",
        "generator_f = make_generator_model(9)\n",
        "discriminator_x = make_discriminator_model()\n",
        "discriminator_y = make_discriminator_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw6AjiYM45gO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator_x.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMOGIot66b_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LAMBDA = 10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GF4SOtp5-GV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_g_optimizer = gen_f_optimizer = tf.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
        "dis_x_optimizer = dis_y_optimizer = tf.optimizers.Adam(lr=0.0002, beta_1=0.5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBsH9kex45gQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# Measures how close to one real images are rated, and how close to zero fake images are rated\n",
        "def discriminator_loss(real, generated):\n",
        "    # Multiplied by 0.5 so that it will train at half-speed\n",
        "    return (loss(tf.ones_like(real), real) + loss(tf.zeros_like(generated), generated)) * 0.5\n",
        "\n",
        "# Measures how real the discriminator believes the fake image is\n",
        "def gen_loss(validity):\n",
        "    return loss(tf.ones_like(validity), validity)\n",
        "\n",
        "# Measures similarity of two images.  Used for cycle and identity loss\n",
        "def image_similarity(image1, image2):\n",
        "    return tf.reduce_mean(tf.abs(image1 - image2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G7HF_uI45gS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def step(real_x, real_y):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        # Setup Dy loss\n",
        "        fake_y = generator_g(real_x, training=True)\n",
        "        gen_g_validity = discriminator_y(fake_y, training=True)\n",
        "        dis_y_loss = discriminator_loss(discriminator_y(real_y, training=True), gen_g_validity)\n",
        "\n",
        "        with tape.stop_recording():\n",
        "            discriminator_y_gradients = tape.gradient(dis_y_loss, discriminator_y.trainable_variables)\n",
        "            dis_y_optimizer.apply_gradients(zip(discriminator_y_gradients, discriminator_y.trainable_variables))\n",
        "\n",
        "        # Setup Dx loss\n",
        "        fake_x = generator_f(real_y, training=True)\n",
        "        gen_f_validity = discriminator_x(fake_x, training=True)\n",
        "        dis_x_loss = discriminator_loss(discriminator_x(real_x, training=True), gen_f_validity)\n",
        "\n",
        "        with tape.stop_recording():\n",
        "            discriminator_x_gradients = tape.gradient(dis_x_loss, discriminator_x.trainable_variables)\n",
        "            dis_x_optimizer.apply_gradients(zip(discriminator_x_gradients, discriminator_x.trainable_variables))\n",
        "\n",
        "        # Setup adversarial losses\n",
        "        gen_g_adv_loss = gen_loss(gen_g_validity)\n",
        "        gen_f_adv_loss = gen_loss(gen_f_validity)\n",
        "\n",
        "        # Setup cycle losses\n",
        "        cyc_x = generator_f(fake_y, training=True)\n",
        "        cyc_x_loss = image_similarity(real_x, cyc_x)\n",
        "\n",
        "        cyc_y = generator_g(fake_x, training=True)\n",
        "        cyc_y_loss =  image_similarity(real_y, cyc_y)\n",
        "\n",
        "        # Setup identity losses\n",
        "        id_x = generator_f(real_x, training=True)\n",
        "        id_x_loss = image_similarity(real_x, id_x)\n",
        "\n",
        "        id_y = generator_g(real_y, training=True)\n",
        "        id_y_loss = image_similarity(real_y, id_y)\n",
        "\n",
        "        # Finalize generator losses and calc gradients\n",
        "        gen_g_loss = gen_g_adv_loss + (cyc_x_loss + cyc_y_loss) * LAMBDA + id_y_loss * 0.5*LAMBDA\n",
        "        gen_f_loss = gen_f_adv_loss + (cyc_x_loss + cyc_y_loss) * LAMBDA + id_x_loss * 0.5*LAMBDA\n",
        "\n",
        "        with tape.stop_recording():\n",
        "            generator_g_gradients = tape.gradient(gen_g_loss, generator_g.trainable_variables)\n",
        "            gen_g_optimizer.apply_gradients(zip(generator_g_gradients, generator_g.trainable_variables))\n",
        "\n",
        "            generator_f_gradients = tape.gradient(gen_f_loss, generator_f.trainable_variables)\n",
        "            gen_f_optimizer.apply_gradients(zip(generator_f_gradients, generator_f.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH6jUyDn45gU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # Sample images\n",
        "    x = next(iter(test_monet.shuffle(1000))).numpy()\n",
        "    y = next(iter(test_photo.shuffle(1000))).numpy()\n",
        "    \n",
        "    # Get predictions for those images\n",
        "    y_hat = generator_g.predict(x.reshape((1, IMG_SIZE, IMG_SIZE, 3)))\n",
        "    x_hat = generator_f.predict(y.reshape((1, IMG_SIZE, IMG_SIZE, 3)))\n",
        "    \n",
        "    plt.figure(figsize=(12, 12))\n",
        "\n",
        "    images = [x[0], y_hat[0], y[0], x_hat[0]]\n",
        "\n",
        "    for i in range(4):\n",
        "        plt.subplot(2, 2, i+1)\n",
        "        plt.imshow(images[i] * 0.5 + 0.5)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDHHaXW1CkPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_images():\n",
        "    # Sample images\n",
        "    x = next(iter(test_monet.shuffle(1000))).numpy()\n",
        "    y = next(iter(test_photo.shuffle(1000))).numpy()\n",
        "    \n",
        "    # Get predictions for those images\n",
        "    y_hat = generator_g.predict(x.reshape((1, IMG_SIZE, IMG_SIZE, 3)))\n",
        "    x_hat = generator_f.predict(y.reshape((1, IMG_SIZE, IMG_SIZE, 3)))\n",
        "    \n",
        "    plt.figure(figsize=(12, 12))\n",
        "\n",
        "    images = [x[0], y_hat[0], y[0], x_hat[0]]\n",
        "\n",
        "    for i in range(4):\n",
        "        plt.subplot(2, 2, i+1)\n",
        "        plt.imshow(images[i] * 0.5 + 0.5)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZCMK-ZV45gW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "epochs=1\n",
        "for epoch in range(epochs):\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    start = time.time()\n",
        "\n",
        "    # Each batch\n",
        "    for k, (real_x, real_y) in enumerate(tf.data.Dataset.zip((train_monet, test_photo))):\n",
        "        if k % 100 == 0: print(k)\n",
        "        # Train step\n",
        "        step(tf.reshape(real_x, (1, IMG_SIZE, IMG_SIZE, 3)), tf.reshape(real_y, (1, IMG_SIZE, IMG_SIZE, 3)))\n",
        "    \n",
        "    # View progress\n",
        "    generate_images()\n",
        "    print('Time taken: {}'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tS2IWx45QF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hbBEQwNMIwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}